# Policy-Gradient-with-Second-Order-Momentum

In this project, we propose an enhancement to traditional policy gradient methods in reinforcement learning by incorporating second order momentum. Our approach aims to improve convergence and exploration-exploitation trade-offs by introducing momentum alongside methods like REINFORCE. We derive the formulation of second order momentum based on existing literature and integrate it into REINFORCE, observing its impact on convergence. We also explored higher order policy gradient algorithms and bias reduction techniques on the augmented model. Overall, this project contributes to advancing the understanding and application of policy gradient algorithms in reinforcement learning, particularly in optimizing convergence and exploration-exploitation dynamics through the integration of second order momentum.
